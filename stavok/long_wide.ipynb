{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2fc1fa8",
   "metadata": {},
   "source": [
    "# Довгий чи широкий\n",
    "\n",
    "В тотальну епоху \"великих даних\" *Python* створює середовище для дослідницького аналізу даних (explanatory data analysis, EDA). EDA допомагає отримати відповіді на запитання чому і як, дає змогу буквально побачити загальні зв'язки або закономірності, візуалізувати недоречності у даних і багато чого іншого. Але реалізація всіх цих зручностей перш за все вимагає налагодження певного технологічного ланцюга обробки даних, рутинною складовою якого є перетворення і, зокрема, переформування даних. У цій статті ми випробуємо такі ефективні методи:\n",
    "\n",
    "- зведення (pivoting) даних;\n",
    "- вибірки даних багатоіндексних і багаторівневих датафреймів."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345bc237",
   "metadata": {},
   "source": [
    "## Під'єднання даних\n",
    "\n",
    "Загалом нас цікавить під'єднання різноманітних джерел відкритих даних: бази даних, веб-скрейпінг соціальних мереж та веб-ресурсів тощо. Але наразі ми обмежимось даними моніторингу якості повітря у вигляді окремого CSV-файлу. \n",
    "\n",
    "Дані були отримані в рамках проєкту [AirZOOM](https://protw.github.io/azreal/#/media/README), виконаного за кошти Громадського Бюджету м. Києва, Україна у 2019-2020 роках. В рамках цих спостережень в середині квітня 2020 спостерігалось значне декількаденне підвищення концентрації аерозолів внаслідок пожеж в чорнобильській зоні відчуження.\n",
    "\n",
    "Отже, скачуємо дані за майже 4 місяці, отримані з чотирьох датчиків моніторингу якості повітря виробництва компанії [Airly](https://airly.org):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161f2d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\miniconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Asus\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.4SP5SUA7CBGXUEOC35YP2ASOICYYEQZZ.gfortran-win_amd64.dll\n",
      "C:\\Users\\Asus\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6512/3440145498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig_dir\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmy_dir\u001b[0m \u001b[1;31m# first, set paths to my directories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m## Read monitoring data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config_dir'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from config_dir import my_dir # first, set paths to my directories\n",
    "\n",
    "## Read monitoring data\n",
    "df = pd.read_csv(my_dir['data'] + r'200421 Chronograf Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48511cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6422844c",
   "metadata": {},
   "source": [
    "Дані у датафреймі `df` представлені 4 стовпчиками: \n",
    "\n",
    "- `time` - часові відмітки з кроком 30 хвилин;\n",
    "- `sensor_id` - номери 4 датчиків `[9969, 10001, 10049, 10050]`;\n",
    "- `val` - значення вимірюваного параметру у мкг/м3;\n",
    "- `factor` - позначення вимірюваного параметру: `['PM25', 'PM10']` - концентрація пилу (аерозолів) в області 2.5 і 10 мкм, відповідно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdff4ac",
   "metadata": {},
   "source": [
    "## Форми представлення таблиць даних\n",
    "\n",
    "Дані представлені тут у так званій stacked (стопкою) формі. Або інакше іх називають довгою (long) формою.\n",
    "\n",
    "Тут треба зробити важливий відступ про форму представлення даних. Розрізняють дві форми представлення таблиць даних: довгу (long) або стопкою (stacked) та широку (wide) або unstacked.\n",
    "\n",
    "Нижче представлений типовий [приклад довгої форми представлення табличних даних](https://plotly.com/python/wide-form/), де кожний рядок представлений записом. Така одновимірна форма типова для таблиць реляційних баз даних або для журналізації подій.\n",
    "\n",
    "|      |      nation |  medal | count |\n",
    "| :--- | ----------: | -----: | ----: |\n",
    "| 0    | South Korea |   gold |    24 |\n",
    "| 1    |       China |   gold |    10 |\n",
    "| 2    |      Canada |   gold |     9 |\n",
    "| 3    | South Korea | silver |    13 |\n",
    "| 4    |       China | silver |    15 |\n",
    "| 5    |      Canada | silver |    12 |\n",
    "| 6    | South Korea | bronze |    11 |\n",
    "| 7    |       China | bronze |     8 |\n",
    "| 8    |      Canada | bronze |    12 |\n",
    "\n",
    "Водночас, коли значення деяких стовпчиків мають тип категорій  (тобто представлені обмеженою кількістю дискретних значень), то тіж самі дані можна презентувати по іншому - у двовимірній формі, коли деякі параметри утворюють стовпчик з унікальними назвами рядків, а інші параметри утворюють рядок з унікальними назвами стовпчиків. Таке представлення називають широким (wide) або unstacked. Тут нижче представлені тіж самі дані, переформовані за описаним підходом:\n",
    "\n",
    "|      |       medal | gold | silver | bronze |\n",
    "| :--- | ----------: | ---: | -----: | -----: |\n",
    "|      |  **nation** |      |        |        |\n",
    "| 0    | South Korea |   24 |     13 |     11 |\n",
    "| 1    |       China |   10 |     15 |      8 |\n",
    "| 2    |      Canada |    9 |     12 |     12 |\n",
    "\n",
    "Форми представлення важливо знати і контролювати під час подання таблиць в якості вхідних даних для пакетів графічного відображення даних. Кожна з форм має свої переваги і обмеження. Так само кожний метод графічної бібліотеки спроможний відображати ту чи іншу форми, але не завжди обидві одночасно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e32fb",
   "metadata": {},
   "source": [
    "## Зведення даних (pivoting)\n",
    "\n",
    "В наших даних `df` стовпчики `sensor_id` і `factor` мають характер категорій, тому їх можна перенести в рядок заголовка з назвою `sensor_id` і `factor`, відповідно. А кожний рядок заповнити їхніми унікальними дискретними значеннями:\n",
    "\n",
    "\n",
    "\n",
    "| sensor_id        | 9969     | 9969     | 10001    | 10001    | 10049    | 10049    | 10050    | 10050    |\n",
    "| ---------------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |\n",
    "| **factor**       | **PM10** | **PM25** | **PM10** | **PM25** | **PM10** | **PM25** | **PM10** | **PM25** |\n",
    "| **Days**         |          |          |          |          |          |          |          |          |\n",
    "| 2020-01-13T00:00 | 0.925    | 0.840    | 28.57    | 26.89    | 26.59    | 24.60    | 29.51    | 25.92    |\n",
    "| 2020-01-13T00:30 | 0.515    | 0.508    | 28.18    | 26.58    | 26.78    | 24.97    | 35.61    | 30.61    |\n",
    "| 2020-01-13T01:00 | 0.365    | 0.347    | 28.51    | 27.00    | 27.33    | 25.33    | 30.80    | 26.90    |\n",
    "| 2020-01-13T01:30 | 0.733    | 0.696    | 28.79    | 27.45    | 27.77    | 25.71    | 33.12    | 28.35    |\n",
    "\n",
    "Такого роду операції можна здійснити процедурою зведення (pivoting), що добре відома в Excel і гарно описана, зокрема, [тут](https://pandas.pydata.org/docs/user_guide/reshaping.html). У пакеті *pandas* датафрейми мають відповідний метод `pivot_table` з простим і зрозумілим синтаксисом, яким ми скористаємось для переформування наших даних `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fdb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re = df.pivot_table(index=\"time\", \n",
    "                       columns=[\"sensor_id\",\"factor\"], \n",
    "                       values=\"val\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503f5dc",
   "metadata": {},
   "source": [
    "## Конвертація часу\n",
    "\n",
    "Для простоти і зручності конвертуємо стовпчик `time` з формату `datetime` у число днів (неціле) з моменту початку серії вимірювання:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "## Convert index from string format to number in days from the 1st data point\n",
    "def convert_index(df):\n",
    "    idt = [datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ') for x in df.index]\n",
    "    idt = np.array([(x - idt[0]).total_seconds()/3600/24 for x in idt])\n",
    "    df.set_index(idt,inplace=True)\n",
    "    df.index.names = ['Days']\n",
    "    return df\n",
    "\n",
    "df_re = convert_index(df_re)\n",
    "#df_re.plot() # For debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba39975",
   "metadata": {},
   "source": [
    "## Вибірка зі складних таблиць\n",
    "\n",
    "Через те, що у нашому випадку кількість рядків заголовків більш ніж 1, питання доступу до обраних стовпчиків такої складної таблиці не таке прямолінійне. Тут складною таблицею ми називаємо або багаторівневу таблицю (з декількома рядками заголовків, як у нашому випадку) або багатоіндексну таблицю (з декількома стовпцями індексів) або і те, і те однчасно.\n",
    "\n",
    "Питання вибірки рядків і стовпців у багаторівневих і багатоіндексних таблицях даних (датафреймах), що зокрема утворюються внаслідок процедури зведення, блискуче висвітлені в [статті](https://towardsdatascience.com/accessing-data-in-a-multiindex-dataframe-in-pandas-569e8767201d).\n",
    "\n",
    "Скористаємось універсальним методом доступу до даних датафрейму `.loc`. \n",
    "\n",
    "Наприклад, вибірка за назвою стовпчика верхнього рівня `9969` виглядає як зазвичай, але поверне всі стовпчики нижнього рівня, що включені до неї, а саме `['PM10', 'PM25']`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id = 9969\n",
    "df_re_sel = df_re.loc[:,sensor_id] # returns columns `factor = ['PM10', 'PM25']`\n",
    "df_re_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed3fa3",
   "metadata": {},
   "source": [
    "Однак аналогічна на вигляд спроба вибірки стовпчика нижчого рівня `'PM25'` призведе до помилки: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e999ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 'PM25'\n",
    "try:\n",
    "    df_re_sel = df_re.loc[:,factor] # *** KeyError: 'PM25'\n",
    "except KeyError as ke:\n",
    "    print(f'KeyError {ke} generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba7915",
   "metadata": {},
   "source": [
    "Тим не менш, вибірка гарно спрацює, якщо задати повну кваліфіковану адресу, починаючи з верхнього рівня, через кортеж (tuple):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re_sel = df_re.loc[:,(sensor_id,factor)]\n",
    "df_re_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5dc382",
   "metadata": {},
   "source": [
    "У такому варіанті запису на будь-якому рівні вже можна задавати декілька стовпчиків, наприклад:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id, factor = (9969,10001), ('PM25')\n",
    "df_re_sel = df_re.loc[:,(sensor_id,factor)]\n",
    "df_re_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a2e6c6",
   "metadata": {},
   "source": [
    "Тепер все ж таки повернімось до вибірки категорій нижче першого рівня. Виявляєтся і це можливо, але іншим методом датафрейму - `.xs`, що називається методом поперечного перерізу (cross-section). Ми вибираємо стовпчики (тобто `axis = 1`) з категорією другого рівня `factor` (тобто `level = 1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re_sel = df_re.xs(factor,level=1,axis=1)\n",
    "df_re_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa074e7",
   "metadata": {},
   "source": [
    "## Графічне відображення\n",
    "\n",
    "Для графічного відображення використаємо графічний пакет *plotly*. Цей пакет обрано тут тому що він гарно підійде для побудови веб-застосунку спільно з іншим пакетом - *streamlit*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser' # 'browser' or 'svg' or other\n",
    "\n",
    "## If 'x' is omitted index with its name is taken, \n",
    "## otherwise put \"x='Days'\" into argument list\n",
    "## If 'y' is omitted all the columns with their names are taken, \n",
    "## otherwise put \"y=list(df_re_sel.columns)\" into argument list\n",
    "title = f'Aerosol concentration {factor} (ug/m3) ' + \\\n",
    "        f'at {len(df_re_sel.columns)} locations in Kyiv, Ukraine, ' +\\\n",
    "        f'starting from {df.time[0][:10]}'\n",
    "fig = px.line(df_re_sel,title=title)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8adb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
